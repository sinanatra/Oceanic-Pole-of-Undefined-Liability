{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TLE for the last known day a satellite was in orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traspose the Satellite Catalogue to a Dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "\n",
    "# Load the TSV file\n",
    "tsv_file_path = './update_tle.tsv'\n",
    "\n",
    "try:\n",
    "    sheet_values = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    sheet_values = pd.DataFrame(columns=['tle_0', 'tle_1', 'norad_cat_num'])\n",
    "\n",
    "# Convert to dictionary for quick lookup\n",
    "tle_dict = {row['norad_cat_num']: row for _, row in sheet_values.iterrows()}\n",
    "\n",
    "# Fetch satellite catalog\n",
    "satcat_url = \"https://celestrak.com/pub/satcat.txt\" # https://api.optimize.esa.int/data/debris_clouds/satcat.txt\n",
    "try:\n",
    "    sat_catalogue = urllib.request.urlopen(satcat_url).read().decode('utf-8').strip().split(\"\\n\")\n",
    "except Exception as e:\n",
    "    raise ConnectionError(f\"Failed to fetch satellite catalog: {e}\")\n",
    "\n",
    "sat_dict = {}\n",
    "for x in sat_catalogue:\n",
    "    try:\n",
    "        sat_dict[x.split()[1]] = x\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to Spacetrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from spacetrack import SpaceTrackClient\n",
    "\n",
    "load_dotenv('.env') \n",
    "\n",
    "username = os.getenv('SPACETRACK_USERNAME')\n",
    "password = os.getenv('SPACETRACK_PASSWORD')\n",
    "\n",
    "st = SpaceTrackClient(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Satellites to skip as they have been already processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "skipped_file = \"skipped_satellites.json\"\n",
    "\n",
    "try:\n",
    "    with open(skipped_file, 'r') as file:\n",
    "        skipped_satellites = json.load(file)\n",
    "except FileNotFoundError:\n",
    "    skipped_satellites = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the TLE to an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing satellites:  14%|█▍        | 8312/59865 [00:31<00:40, 1286.50it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_entries = []\n",
    "\n",
    "for key in tqdm(sat_dict.keys(), desc=\"Processing satellites\"):\n",
    "    if str('n_' + key) not in tle_dict and key not in skipped_satellites:\n",
    "        try:\n",
    "            if \"-\" in sat_dict[key][75:85] and \"N/A\" not in sat_dict[key][119:127]:\n",
    "                lines = st.tle_latest(norad_cat_id=[key], format='tle')\n",
    "                lines = lines.split(\"\\n\")\n",
    "                \n",
    "                for line1, line2 in zip(*[iter(lines[-3:-1])]*2):\n",
    "                    update_line = [str(line1), str(line2), str('n_' + key)]\n",
    "                    # print(update_line)\n",
    "                    new_entries.append(update_line)\n",
    "                    skipped_satellites.append(key)\n",
    "                    # Limit the API request\n",
    "                    time.sleep(2) # 20 advised\n",
    "            else:\n",
    "                skipped_satellites.append(key)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing satellite {key}: {e}\")\n",
    "            skipped_satellites.append(key)\n",
    "    else:\n",
    "         skipped_satellites.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the satellites to skip into a json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(skipped_file, 'w') as file:\n",
    "    json.dump(skipped_satellites, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a csv for the TLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if new_entries:\n",
    "    new_df = pd.DataFrame(new_entries, columns=['tle_0', 'tle_1', 'norad_cat_num'])\n",
    "    updated_sheet = pd.concat([sheet_values, new_df])\n",
    "    updated_sheet.to_csv(tsv_file_path, sep='\\t', index=False)\n",
    "else:\n",
    "    print(\"No new entries to update.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
