{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import codecs\n",
    "import ephem\n",
    "from ephem import degree\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Space Catalogue as a dictionary\n",
    "satcat = \"https://celestrak.com/pub/satcat.txt\"\n",
    "sat_catalogue = urllib.request.urlopen(satcat).read().decode('utf-8').strip().split(\"\\n\")\n",
    "\n",
    "sat_dict = {}\n",
    "for x in sat_catalogue:\n",
    "    try:\n",
    "        sat_dict[x.split()[1]] = x\n",
    "    except IndexError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import ephem\n",
    "\n",
    "# Open the local TLE data file\n",
    "local_tle_file = \"update_tle.tsv\"\n",
    "output_file = \"output/data.json\"\n",
    "\n",
    "# Read the local TLE data file\n",
    "with open(local_tle_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    sheetValues = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 00008U 58004  B 60095.16166626  .02607090 +00000-0 +00000-0 0  9993', '2 00008 065.0599 163.5585 0088318 135.6760 224.6847 16.28328133100004', 'n_00008']\n"
     ]
    }
   ],
   "source": [
    "print(sheetValues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00008\n",
      "258931.375\n",
      "205694.546875\n",
      "yee\n",
      "\n",
      "Finished parsing!\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for i in range(1, len(sheetValues)):\n",
    "    row = sheetValues[i]\n",
    "    tle_line0 = row[0]\n",
    "    tle_line1 = row[1]\n",
    "    norad_id = row[2].replace('n_', '')\n",
    "    possible_satellite_reentry_date = sat_dict[norad_id][75:85] + \" \" + \"00:00:00\"\n",
    "    \n",
    "    print(norad_id)\n",
    "\n",
    "    try:\n",
    "        # Read TLE\n",
    "        name = \"sat_data\"\n",
    "        tle_rec = ephem.readtle(name, tle_line0, tle_line1)\n",
    "        tle_rec.compute(possible_satellite_reentry_date)\n",
    "        \n",
    "        # Set reentry threshold to 122 km (122000 meters)\n",
    "        reentry_threshold = 122000  # official entry interface by ESA and NASA\n",
    "    \n",
    "        # Check if the initial elevation is above or below the threshold\n",
    "        if int(tle_rec.elevation) >= reentry_threshold:\n",
    "\n",
    "            d = datetime.datetime.strptime(possible_satellite_reentry_date, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "            # Check whether the debris reenters after max two days \n",
    "            for i in range(0, 48):  # 48 hours\n",
    "                parseHour = d + timedelta(hours=i)\n",
    "                tle_rec.compute(parseHour)\n",
    "                print(tle_rec.elevation)\n",
    "\n",
    "                if int(tle_rec.elevation) <= reentry_threshold:  # threshold of reentry   \n",
    "                    print(\"yee\")\n",
    "\n",
    "                    data_list.append({\n",
    "                        \"tle_0\": tle_line0,\n",
    "                        \"tle_1\": tle_line1,\n",
    "                        \"lat\": tle_rec.sublat / ephem.degree,\n",
    "                        \"lon\": tle_rec.sublong / ephem.degree,\n",
    "                        \"norad_cat_num\": norad_id,\n",
    "                        \"satellite_name\": sat_dict[norad_id][23:47].strip(),\n",
    "                        \"ownership\": sat_dict[norad_id][49:54].strip(),\n",
    "                        \"launch_date\": sat_dict[norad_id][56:66].strip(),\n",
    "                        \"satellite_decay\": sat_dict[norad_id][75:85].strip(),\n",
    "                        \"satellite_decay_hour\": str(parseHour),\n",
    "                        \"rcs\": sat_dict[norad_id][119:127].strip()\n",
    "                    })\n",
    "                    \n",
    "                    # Add further detailed tracking points\n",
    "                    for offset_minutes in [2, 6]:\n",
    "                        nextMinutes = parseHour + timedelta(minutes=offset_minutes)\n",
    "                        tle_rec.compute(nextMinutes)\n",
    "                        data_list.append({\n",
    "                            \"tle_0\": tle_line0,\n",
    "                            \"tle_1\": tle_line1,\n",
    "                            \"lat\": tle_rec.sublat / ephem.degree,\n",
    "                            \"lon\": tle_rec.sublong / ephem.degree,\n",
    "                            \"norad_cat_num\": norad_id,\n",
    "                            \"satellite_name\": sat_dict[norad_id][23:47].strip(),\n",
    "                            \"ownership\": sat_dict[norad_id][49:54].strip(),\n",
    "                            \"launch_date\": sat_dict[norad_id][56:66].strip(),\n",
    "                            \"satellite_decay\": sat_dict[norad_id][75:85].strip(),\n",
    "                            \"satellite_decay_hour\": str(nextMinutes),\n",
    "                            \"rcs\": sat_dict[norad_id][119:127].strip()\n",
    "                        })\n",
    "                    break\n",
    "\n",
    "        elif int(tle_rec.elevation) <= reentry_threshold:  # threshold of reentry\n",
    "\n",
    "            for offset_minutes in [0, 2, 6]:\n",
    "                nextMinutes = d + timedelta(minutes=offset_minutes)\n",
    "                tle_rec.compute(nextMinutes)\n",
    "                data_list.append({\n",
    "                    \"tle_0\": tle_line0,\n",
    "                    \"tle_1\": tle_line1,\n",
    "                    \"lat\": tle_rec.sublat / ephem.degree,\n",
    "                    \"lon\": tle_rec.sublong / ephem.degree,\n",
    "                    \"norad_cat_num\": norad_id,\n",
    "                    \"satellite_name\": sat_dict[norad_id][23:47].strip(),\n",
    "                    \"ownership\": sat_dict[norad_id][49:54].strip(),\n",
    "                    \"launch_date\": sat_dict[norad_id][56:66].strip(),\n",
    "                    \"satellite_decay\": sat_dict[norad_id][75:85].strip(),\n",
    "                    \"satellite_decay_hour\": str(nextMinutes),\n",
    "                    \"rcs\": sat_dict[norad_id][119:127].strip()\n",
    "                })\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "print(\"\\nFinished parsing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data to minified JSON file\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    json.dump(data_list, json_file, ensure_ascii=False, separators=(',', ':'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
